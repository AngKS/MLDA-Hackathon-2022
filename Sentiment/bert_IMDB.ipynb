{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stx6\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import os\n",
    "import shutil"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'This is a string'>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const = tf.constant([\"This is a string\", \"This is another string\"])\n",
    "const[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84125825/84125825 [==============================] - 21s 0us/step\n"
     ]
    }
   ],
   "source": [
    "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "\n",
    "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n",
    "                                  untar=True, cache_dir='.',\n",
    "                                  cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "\n",
    "# remove unused folders to make it easier to load the data\n",
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/test',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
      "Label : 0 (neg)\n",
      "Review: b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n",
      "Label : 0 (neg)\n",
      "Review: b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'\n",
      "Label : 1 (pos)\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(f'Review: {text_batch.numpy()[i]}')\n",
    "    label = label_batch.numpy()[i]\n",
    "    print(f'Label : {label} ({class_names[label]})')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 512), dtype=float32, numpy=\narray([[ 0.98970085,  0.94875145,  0.1473233 , ...,  0.25531632,\n        -0.60437495, -0.06837161],\n       [ 0.9279229 ,  0.994185  , -0.13640113, ...,  0.5561989 ,\n         0.24758223, -0.6366758 ]], dtype=float32)>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_preprocess(sentences)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']\n",
    "\n",
    "get_sentence_embeding([\n",
    "    \"500$ discount. hurry up\",\n",
    "    \"Bhavin, are you up for a volleybal game tomorrow?\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'default': (None,   28763649    ['preprocessing[0][0]',          \n",
      "                                512),                             'preprocessing[0][1]',          \n",
      "                                 'sequence_output':               'preprocessing[0][2]']          \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 512),                                                       \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 512),                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)]}                                               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['BERT_encoder[0][5]']           \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 1)            513         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,764,162\n",
      "Trainable params: 28,764,161\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)\n",
    "\n",
    "\n",
    "classifier_model = build_classifier_model()\n",
    "classifier_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stx6\\miniconda3\\envs\\tf2.8\\lib\\site-packages\\keras\\backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 85s 129ms/step - loss: 0.4811 - binary_accuracy: 0.7592 - val_loss: 0.3991 - val_binary_accuracy: 0.8228\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 77s 124ms/step - loss: 0.3289 - binary_accuracy: 0.8589 - val_loss: 0.3755 - val_binary_accuracy: 0.8450\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 80s 128ms/step - loss: 0.2539 - binary_accuracy: 0.8959 - val_loss: 0.3722 - val_binary_accuracy: 0.8500\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 78s 125ms/step - loss: 0.1945 - binary_accuracy: 0.9256 - val_loss: 0.4364 - val_binary_accuracy: 0.8480\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 81s 129ms/step - loss: 0.1582 - binary_accuracy: 0.9414 - val_loss: 0.4566 - val_binary_accuracy: 0.8508\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n",
    "\n",
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)\n",
    "\n",
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 55s 70ms/step - loss: 0.4390 - binary_accuracy: 0.8581\n",
      "Loss: 0.4389951229095459\n",
      "Accuracy: 0.8581200242042542\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b'INFERNO starts off with a fairly impressive for a TVM starscape effect . We`re also introduced to a scientist who`s called Heller . Don`t you get it ? Heller , Hell-er , Inferno . So I guess someone on the production had some intelligence . However it does become more and more obvious as the TVM progresses that intelligence has been discarded throughout the storyline in order to appeal to an American TVM audience <br /><br />The story itself is overwhelmed by subplots featuring umpteen stock TVM characters like the tough liberal schoolteacher who`s trying to save a home boy from a life of crime , the doctor who`s lost his medical licence etc . In fact the story concentrates far more on these characters than the approaching disaster that all the potential tension and drama the scenario might have had soon goes up in a puff of smoke , and being a TVM we just know that there won`t be a downbeat ending <br /><br />There is an onscreen problem I noticed and that is everytime there`s an explosion there`s a massive fireball which looks ridiculous not to mention physically impossible . Look at the scene where the national guard are in a fight with a gang . A soldier fires a grenade into a tower block and the whole building explodes in a fire ball . What a small greanade containing no more than a few ounces of high explosive can do that ! No it can`t . There`s also another scene of army engineers blowing up a dam with plastic explosive and the same fireball effect is seen . Can directors please note that high explosive is not the same as napalm <br /><br />Having said that I did find INFERNO highly watchable for a TVM and at no time did I find myself wanting to turn it off . It did have some potential and let me repeat the special effects are fairly good considering the budget and it`s not as bad a TVM as some people are making out'\n",
      "Label : 0 (neg)\n",
      "Review: b'I read a few reviews of the movie and got the impression that it was not as good as the previous Karate Kid installments. Although my favorite is still Karate Kid II, I felt this fourth installment of the movie series was consistent with the others and had some important lessons to share. Unlike the previous versions, the karate student is a female teenager who takes a somewhat different learning path, rather than a male teenager. Maggi finds this a little more challenging, but rises to the occasion. The plot twists are believable and predictable. I found that the bad guys are a little one dimensional, but this weakness is present in all the installments in varying degrees. The camera work is impressive and pans across some beautiful scenery from time to time. The Zen monastery is both austere and charming. The Zen monks add some humor and lightness to the narrative flow. I liked the \"Zen Bowling\" scenes which are a humorous counterpoint to the more serious Zen archery scene earlier on. The quality level of the movie is like a good TV series. The music chosen for the background is very good, especially with the Little River Band playing \"Listen to Your Heart\". The lessons in the movie are valuable and worthwhile to learn. They feel faithful to the spirit of karate and take care not to over-glorify the fighting part. All in all, I enjoyed it.'\n",
      "Label : 1 (pos)\n",
      "Review: b'Dr Steven Segal saves the world from a deadly virus outbreak. This movie strikes me as foolish earnestness that has morphed into an unintended camp classic (the best kind). Memorable lines include \"Knowledge is like a deer. Chase it, and it will run away from you\" and \"Drink this. It will make you feel better.\" It is so sublimely bad -- they couldn\\'t have made it any worse if they tried.<br /><br />Segal tries to convince you that he is 1. sensitive -- by saving a stricken pony; 2. a good father -- by a saccharine cooking scene for his daughter; 3. a man of science -- by looking at a fake spectrum; 4. in tune with nature -- by using homeopathic remedies; 5. politically correct and multicultural -- by having Indian friends; 6. an iconoclast -- by opening a rural practice after a former life in a national research lab; and 7. an action hero -- by being really fat but yet can still fight. ROTFL.<br /><br />It\\'s good to see on as a late-night Saturday flick, with friends, preferably (but not necessarily!) inebriated.'\n",
      "Label : 0 (neg)\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in test_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(f'Review: {text_batch.numpy()[i]}')\n",
    "    label = label_batch.numpy()[i]\n",
    "    print(f'Label : {label} ({class_names[label]})')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "[[0.5804627]]\n"
     ]
    }
   ],
   "source": [
    "result = classifier_model.predict(['This product is '])\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.4943401]], dtype=float32)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}